= Install Advanced Management and GitOps Operators
include::_attributes.adoc[]

This section will guide you through the ACM and GitOps CD Operators installation and the ACM/GitOps integration in order to deploy application both local and remote clusters. 

Hereâ€™s a list of required operators to install through the Operator Lifecycle Manager (OLM), which manages the installation, upgrade, and removal:

 - **ACM Operator**
 
image::deploy/deploy01.png[]
 
 - **GitOps Operator**
 
image::deploy/deploy02.png[]

NOTE: The OpenShift Container Platform provided in this lab meets the minimal https://access.redhat.com/documentation/en-us/red_hat_advanced_cluster_management_for_kubernetes/2.6/html/install/installing#requirements-and-recommendations[requirements] from the official documentation. The cluster hub components will be installed on worker nodes, no https://access.redhat.com/documentation/en-us/red_hat_advanced_cluster_management_for_kubernetes/2.6/html/install/installing#installing-on-infra-node[infrastructure] nodes will be provided.

NOTE: OpenShift Container Platform required access: Cluster administrator (cluster-admin) permissions.

[#install]
== Install ACM Operator

We will go through `oc kustomize` command in order to perform ACM Operator installation:

- Clone repository 

[.lines_space]
[.console-input]
[source,bash, subs="+macros,+attributes"]
----
git clone https://github.com/xbryan1/rhte-2023-acm-apps
----

- Directories structure:

image::deploy/deploy03.png[]

[.lines_space]
[.console-input]
[source,bash, subs="+macros,+attributes"]
----
cd rhte-2023-acm-apps/rhte2023/; oc kustomize 00_boostrap/base/acm_operator/base
----

image::deploy/deploy04.png[]

- Enable master node scheduling

WARNING: This configuration is not recommended for production.

[.lines_space]
[.console-input]
[source,bash, subs="+macros,+attributes"]
----
oc replace -k 00_boostrap/base/openshift/base
----

image::deploy/deploy05.png[]

- Install ACM Operator:

[.lines_space]
[.console-input]
[source,bash, subs="+macros,+attributes"]
----
oc apply -k 00_boostrap/base/acm_operator/base
----

image::deploy/deploy06.png[]

After installing the ACM Operator we also need to create the CRD object `MultiClusterHub`. 

- Create `MultiClusterHub`:

[.lines_space]
[.console-input]
[source,bash, subs="+macros,+attributes"]
----
oc apply -k 00_boostrap/base/acm_multiclusterhub/base
----

image::deploy/deploy07.png[]

Wait until the ACM Operatator is installed. It can take up to 10 minutes for the MultiClusterHub custom resource status to display as Running in the `status.phase` field after you run the command:

[.lines_space]
[.console-input]
[source,shell, subs="+macros,+attributes"]
----
oc get mch -o=jsonpath='{.items[0].status.phase}' -n open-cluster-management
----

image::deploy/deploy08.png[]

If the multiclusterhub is not in `Running` status after a while, check the operator logs or pods status as follows:

[.lines_space]
[.console-input]
[source,bash, subs="+macros,+attributes"]
----
oc logs multiclusterhub-operator-xxx-xxx -n open-cluster-management

oc get pod -n open-cluster-management
----

[#console]
== Access to the ACM Web Console

After the ACM Operator is installed, it provides dashboard UI. We can access it through the OpenShift `Route`. List routes in the `open-cluster-management` namespace and get address of console  https://multicloud-console.apps.<YOUR_DOMAIN>.

image::deploy/deploy09.png[]

Multicluster Hub has to be installed and the RHACM Console accesible to proceed with the next steps.

[#gitops]
== Install GitOps Operator

Run the following command to install the GitOps Operator based on ArgoCD. 

[.lines_space]
[.console-input]
[source,bash, subs="+macros,+attributes"]
----
oc apply -k 00_boostrap/base/gitops_operator/base/
----

image::deploy/deploy10.png[]

[#gitopsacm]
== Integrate GitOps and ACM

ACM introduces a new `gitopscluster` resource kind, which connects to a `placement` resource to determine which clusters to import into Argo CD. This integration allows you to expand your fleet, while having Argo CD automatically engage in working with your new clusters. This means if you leverage Argo CD `ApplicationSets`, your application payloads are automatically applied to your new clusters as they are registered by RHACM in your Argo CD instances.

image::deploy/deploy18.png[]

- Run the following commands to perform the GitOps Operator integration with RHACM

[.lines_space]
[.console-input]
[source,bash, subs="+macros,+attributes"]
----
oc apply -k 00_boostrap/base/gitops_acm/base/
----

image::deploy/deploy11.png[]

- Check that ArgoCD console is accessible and pods are in `Running` status

[.lines_space]
[.console-input]
[source,bash, subs="+macros,+attributes"]
----
oc get route -n openshift-gitops

oc get pods -n openshift-gitops
----

image::deploy/deploy12.png[]

or from the Openshift Console 

image::deploy/deploy13.png[]

image::deploy/deploy14.png[]

- Login into the ArgoCD Console with the Openshift credentials. 

image::deploy/deploy15.png[]

[#managedcluster]
== Label local-cluster as a GitOps Cluster

After the ACM/GitOps integration is done, you will label `local-cluster` (ACM) with `ClusterSet rhte2023-gitops-clusters` and environment `development`. This configuration will let us deploy applications into this Openshift cluster.

[.lines_space]
[.console-input]
[source,bash, subs="+macros,+attributes"]
----
oc label ManagedCluster local-cluster cluster.open-cluster-management.io/clusterset=rhte2023-gitops-clusters --overwrite
oc label ManagedCluster local-cluster gitops-cluster=true environment=development
----

and check that cluster `local-cluster` is added as an ArgoCD Cluster from the **ArgoCD Console > Settings > Clusters** where we expect to see `local-cluster` as one of the clusters

image::deploy/deploy16.png[]

image::deploy/deploy17.png[]